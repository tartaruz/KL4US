{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import Data\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CF:\n",
    "    def __init__(self, k, min_k, sim, user_based):\n",
    "        self.dataset = Data().load_dataset('pickeledDataset') # Load pickeled dataset (or preprocess the dataset if the pickle does not exist)\n",
    "        self.users = self.dataset[['userId', 'documentId', 'activeTime']] # Create a user dataframe\n",
    "        \n",
    "        self.scaler = StandardScaler() # Init scaler\n",
    "        \n",
    "        self.users['activeTime'] = self.scaler.fit_transform(np.array(self.users['activeTime']).reshape(-1, 1)) # Scale all active times \n",
    "\n",
    "        self.users.columns = ['userId', 'documentId', 'rating'] # Change \"activeTime\" to \"rating\"\n",
    "\n",
    "        rating_scale=(self.users['rating'].min(), self.users['rating'].max()) # Rating scale to be used (min(activeTime) - max(activeTime))\n",
    "        self.data = Dataset.load_from_df(self.users[['userId', 'documentId', 'rating']], reader=Reader(rating_scale=rating_scale)) # Set CF data as user dataframe\n",
    "        \n",
    "        self.trainset, self.testset = train_test_split(self.data, test_size=0.2) # Split data into 80% train and 20% test\n",
    "        self.trainsetfull = self.data.build_full_trainset() # Build full trainset\n",
    "\n",
    "        self.trainset_iids = list(self.trainset.all_items()) # Scikit-learn uses \"inner ids\", get all the inner ids for items\n",
    "        self.trainset_uids = list(self.trainset.all_users()) # Get all inner ids for users \n",
    "\n",
    "        self.iid_converter = lambda x: self.trainset.to_raw_iid(x) # Converter for innerid and actual id for items\n",
    "        self.uid_converter = lambda x: self.trainset.to_raw_uid(x) # Converter for innerid and actual id for users\n",
    "\n",
    "        self.trainset_raw_iids = list(map(self.iid_converter, self.trainset_iids)) # Store list with raw item ids\n",
    "        self.trainset_raw_uids = list(map(self.uid_converter, self.trainset_uids)) # Store list with raw user ids\n",
    "\n",
    "        self.k = k # Set k to be used in KNN\n",
    "        self.min_k = min_k # Minimum neighbours to consider.\n",
    "\n",
    "        # Define similarity options\n",
    "        self.sim_option = {\n",
    "            'name':sim, 'user_based':user_based\n",
    "        }\n",
    "        \n",
    "        # Define algorithm to be used in the CF.\n",
    "        self.algo = KNNWithMeans(\n",
    "            k = self.k, min_k = self.min_k, sim_option = self.sim_option\n",
    "        )\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"Train model on trainset\"\"\"\n",
    "\n",
    "        self.algo.fit(self.trainset)\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"Predict items\"\"\"\n",
    "\n",
    "        return self.algo.test(self.testset)\n",
    "\n",
    "    def predict_all(self):\n",
    "        \"\"\"Recommend for all users\"\"\"\n",
    "\n",
    "        testset = pd.DataFrame(self.testset, columns=['uid', 'iid', 'rating'])\n",
    "        return self.algo.test(testset.values.tolist())\n",
    "\n",
    "    def predict_user(self, user):\n",
    "        \"\"\"Recommend for one user\"\"\"\n",
    "\n",
    "        testset = pd.DataFrame(self.testset, columns=['uid', 'iid', 'rating'])\n",
    "        return self.algo.test(testset[testset['uid'] == user].values.tolist())\n",
    "\n",
    "    def predictions_to_dataframe(self, predictions):\n",
    "        \"\"\"Map predictions to Pandas DataFrame\"\"\"\n",
    "\n",
    "        return pd.DataFrame(predictions)\n",
    "\n",
    "    def sort_predictions(self, predictions):\n",
    "        \"\"\"Sort the predictions\"\"\"\n",
    "\n",
    "        return predictions.sort_values(\"est\", ascending=False, inplace=False)\n",
    "\n",
    "    def scale_predictions(self, predictions):\n",
    "        \"\"\"Scale predictions back to original aciveTime\"\"\"\n",
    "\n",
    "        predictions['r_ui'] = self.scaler.inverse_transform(np.array(predictions['r_ui']).reshape(-1,1))\n",
    "        predictions['est'] = self.scaler.inverse_transform(np.array(predictions['est']).reshape(-1,1))\n",
    "        return predictions\n",
    "\n",
    "    def get_top_n(self, predictions, user=None, n=10):\n",
    "        \"\"\"Get top N predictions\"\"\"\n",
    "\n",
    "        if user is None:\n",
    "            return predictions.sort_values('est', inplace=True, ascending=False).head(n)\n",
    "        return predictions[predictions['uid'] == user].sort_values('est', inplace=True, ascending=False).head(n)\n",
    "\n",
    "    def precision_recall(self, predictions, k=10, threshold=44):\n",
    "        \"\"\"Calculate precision@k and recall@k for predictions\"\"\"\n",
    "\n",
    "        user_est_true = defaultdict(list)\n",
    "        for _, row in predictions.iterrows():\n",
    "            user_est_true[row['uid']].append((row['est'], row['r_ui']))\n",
    "\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        for uid, user_ratings in user_est_true.items():\n",
    "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                                        for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "        return precisions, recalls\n",
    "\n",
    "    def ARHR(self, predictions, k=5, threshold=44):\n",
    "        user_est_true = defaultdict(list)\n",
    "        for i, row in predictions.iterrows():\n",
    "            user_est_true[row['uid']].append((row['est'], row['r_ui']))\n",
    "\n",
    "        reciprocal_rank = 0\n",
    "        for uid in user_est_true:\n",
    "            for i, user_ratings in enumerate(user_est_true[uid][:k]):\n",
    "                reciprocal_rank += (user_ratings[0] >= threshold and user_ratings[1] >= threshold)/(i+1)\n",
    "\n",
    "        return reciprocal_rank/len(list(user_est_true.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-655a0576a7bb>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.users['activeTime'] = self.scaler.fit_transform(np.array(self.users['activeTime']).reshape(-1, 1)) # Scale all active times\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8476\n",
      "Precision: 0.8645999999999975\n",
      "Recall: 0.048210084458815555\n",
      "ARHR: 1.9824333333333346\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    k = 5 # K - neighbors.\n",
    "    min_k = 5 # Minimum neighbours to consider.\n",
    "    similarity_measure = 'pearson' # What similarity measure that should be used in KNN\n",
    "    user_based = True # User based or item-based\n",
    "\n",
    "    cf = CF(k, min_k, similarity_measure, user_based) # Create CF-object\n",
    "    cf.train() # Traing the model\n",
    "\n",
    "    predictions = cf.predict_all() # Recommend articles for all users in dataset.\n",
    "\n",
    "    accuracy.mse(predictions) # Print MSE\n",
    "\n",
    "    predictions = cf.sort_predictions(cf.scale_predictions(cf.predictions_to_dataframe(predictions))) # Process predictions.\n",
    "    \n",
    "    precisions, recalls = cf.precision_recall(predictions, k=k) # Get precision and recall\n",
    "\n",
    "    print(f'Precision: {sum(precisions.values())/len(list(precisions.keys()))}') # Print mean precision\n",
    "    print(f'Recall: {sum(recalls.values())/len(list(recalls.keys()))}') # Print mean recall\n",
    "    print(f'ARHR: {cf.ARHR(predictions, k=k)}') # Print ARHR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***K = 5*** <br>\n",
    "MSE: 0.8476<br>\n",
    "Precision: 0.8645999999999975<br>\n",
    "Recall: 0.048210084458815555<br>\n",
    "ARHR: 1.9824333333333346<br>\n",
    "\n",
    "\n",
    "***K = 10*** <br>\n",
    "MSE: 0.8166 <br>\n",
    "Precision: 0.8674555555555523<br>\n",
    "Recall: 0.0963086921949008<br>\n",
    "ARHR: 2.5639087301587162<br>\n",
    "\n",
    "\n",
    "***K = 15*** <br>\n",
    "MSE: 0.7910 <br>\n",
    "Precision: 0.8639972721722675 <br>\n",
    "Recall: 0.1434304175474624 <br>\n",
    "ARHR: 2.9040454906203976<br>\n",
    "\n",
    "\n",
    "***K = 20*** <br>\n",
    "MSE: 0.7723 <br>\n",
    "Precision: 0.866314455178467 <br>\n",
    "Recall: 0.1898203508445937 <br>\n",
    "ARHR: 3.1473988132180537 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
